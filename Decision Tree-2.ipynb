{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30c27ed7-7eb4-44bd-bd43-ad41524c3b0d",
   "metadata": {},
   "source": [
    "You are a data scientist working for a healthcare company, and you have been tasked with creating a \r\n",
    "decision tree to help identify patients with diabetes based on a set of clinical variables. You have been \r\n",
    "given a dataset (diabetes.csv) with the following variables:\r\n",
    "\r\n",
    "1. Pregnancies: Number of times pregnant (integer)\r\n",
    "\r\n",
    "2. Glucose: Plasma glucose concentration a 2 hours in an oral glucose tolerance test (integer)\r\n",
    "\r\n",
    "3. BloodPressure: Diastolic blood pressure (mm Hg) (integer)\r\n",
    "\r\n",
    "4. SkinThickness: Triceps skin fold thickness (mm) (integer)\r\n",
    "\r\n",
    "5. Insulin: 2-Hour serum insulin (mu U/ml) (integer)\r\n",
    "\r\n",
    "6. BMI: Body mass index (weight in kg/(height in\n",
    "Ans:-Great! To create a decision tree for identifying patients with diabetes based on the given clinical variables, we can follow these general steps using Python and popular libraries such as pandas and scikit-learn.\r\n",
    "\r\n",
    "Assuming you have a CSV file named \"diabetes.csv\" with columns named \"Pregnancies,\" \"Glucose,\" \"BloodPressure,\" \"SkinThickness,\" \"Insulin,\" \"BMI,\" and a target variable \"Outcome\" indicating whether a patient has diabetes (1 for positive, 0 for negative). m)^2) (float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6ca6ca-4bd2-4e2f-81be-d3cf871adf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.tree import export_text\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'path/to/diabetes.csv'  # Replace with the actual path to your CSV file\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(df.head())\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = df.drop('Outcome', axis=1)\n",
    "y = df['Outcome']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Decision Tree model\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Display the evaluation metrics\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print('\\nConfusion Matrix:\\n', conf_matrix)\n",
    "print('\\nClassification Report:\\n', classification_rep)\n",
    "\n",
    "# Display the decision tree rules\n",
    "tree_rules = export_text(model, feature_names=list(X.columns))\n",
    "print('\\nDecision Tree Rules:\\n', tree_rules)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970419ee-7c00-405c-997c-d55d91c5633f",
   "metadata": {},
   "source": [
    "7. DiabetesPedigreeFunction: Diabetes pedigree function (a function which scores likelihood of diabetes \n",
    "based on family history) (float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d90dac1-0714-4872-b425-9c95b1c5d6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.tree import export_text\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'path/to/diabetes.csv'  # Replace with the actual path to your CSV file\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(df.head())\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = df.drop('Outcome', axis=1)\n",
    "y = df['Outcome']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Decision Tree model\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Display the evaluation metrics\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print('\\nConfusion Matrix:\\n', conf_matrix)\n",
    "print('\\nClassification Report:\\n', classification_rep)\n",
    "\n",
    "# Display the decision tree rules\n",
    "tree_rules = export_text(model, feature_names=list(X.columns))\n",
    "print('\\nDecision Tree Rules:\\n', tree_rules)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089cf9e9-128e-4600-92b6-64d78c4af2c7",
   "metadata": {},
   "source": [
    "8. Age: Age in years (integer)\n",
    "\n",
    "9. Outcome: Class variable (0 if non-diabetic, 1 if diabetic) (integer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e7c9c9-984a-4fbf-8d30-89eb4a4e3d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.tree import export_text\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'path/to/diabetes.csv'  # Replace with the actual path to your CSV file\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(df.head())\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = df.drop('Outcome', axis=1)\n",
    "y = df['Outcome']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Decision Tree model\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Display the evaluation metrics\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print('\\nConfusion Matrix:\\n', conf_matrix)\n",
    "print('\\nClassification Report:\\n', classification_rep)\n",
    "\n",
    "# Display the decision tree rules\n",
    "tree_rules = export_text(model, feature_names=list(X.columns))\n",
    "print('\\nDecision Tree Rules:\\n', tree_rules)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a408c3a-23d7-42cf-bb26-58b552d81a22",
   "metadata": {},
   "source": [
    "Q1. Import the dataset and examine the variables. Use descriptive statistics and visualizations to \n",
    "understand the distribution and relationships between the variables.\n",
    "Ans:-Certainly! To import the dataset and examine the variables using descriptive statistics and visualizations, you can use Python with libraries such as pandas, matplotlib, and seaborn. Below is an example code snippet to get you started. Make sure to replace 'path/to/diabetes.csv' with the actual path to your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57cee47-1fec-44c7-94e2-ac16bed9d50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'path/to/diabetes.csv'  # Replace with the actual path to your CSV file\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(df.head())\n",
    "\n",
    "# Descriptive statistics\n",
    "print(\"\\nDescriptive Statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Pairwise correlation heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
    "plt.title('Pairwise Correlation Heatmap')\n",
    "plt.show()\n",
    "\n",
    "# Distribution of numerical variables\n",
    "df.hist(figsize=(12, 10))\n",
    "plt.suptitle('Distribution of Numerical Variables', y=0.92)\n",
    "plt.show()\n",
    "\n",
    "# Box plots for key variables\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.boxplot(x='Outcome', y='Glucose', data=df)\n",
    "plt.title('Box Plot for Glucose')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.boxplot(x='Outcome', y='BMI', data=df)\n",
    "plt.title('Box Plot for BMI')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.boxplot(x='Outcome', y='Age', data=df)\n",
    "plt.title('Box Plot for Age')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb409d82-b8b7-4360-9bbb-86574aebf970",
   "metadata": {},
   "source": [
    "Q2. Preprocess the data by cleaning missing values, removing outliers, and transforming categorical \n",
    "variables into dummy variables if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b49492-400f-40ac-80c1-2e2e361c7e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'path/to/diabetes.csv'  # Replace with the actual path to your CSV file\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display missing values\n",
    "print(\"Missing Values Before Preprocessing:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Visualize missing values\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(df.isnull(), cbar=False, cmap='viridis')\n",
    "plt.title('Missing Values Heatmap')\n",
    "plt.show()\n",
    "\n",
    "# Handling missing values (replace with median for numerical features)\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "df_filled = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "\n",
    "# Outlier detection and removal using Isolation Forest\n",
    "outlier_detector = IsolationForest(contamination=0.05, random_state=42)\n",
    "outliers = outlier_detector.fit_predict(df_filled)\n",
    "df_cleaned = df_filled.loc[outliers != -1]\n",
    "\n",
    "# Transform categorical variables into dummy variables (if any)\n",
    "# Example: df_cleaned = pd.get_dummies(df_cleaned, columns=['CategoricalVariable'])\n",
    "\n",
    "# Display missing values after preprocessing\n",
    "print(\"\\nMissing Values After Preprocessing:\")\n",
    "print(df_cleaned.isnull().sum())\n",
    "\n",
    "# Visualize missing values after preprocessing\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(df_cleaned.isnull(), cbar=False, cmap='viridis')\n",
    "plt.title('Missing Values Heatmap After Preprocessing')\n",
    "plt.show()\n",
    "\n",
    "# Additional preprocessing steps (if needed), such as scaling numerical features\n",
    "# Example: scaler = StandardScaler()\n",
    "# df_scaled = pd.DataFrame(scaler.fit_transform(df_cleaned), columns=df_cleaned.columns)\n",
    "\n",
    "# Split the data into features and target variable\n",
    "X = df_cleaned.drop('Outcome', axis=1)\n",
    "y = df_cleaned['Outcome']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Now, X_train, X_test, y_train, y_test can be used for further analysis or modeling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b2f250-ce01-4fb2-8983-5a4c5017f834",
   "metadata": {},
   "source": [
    "Q3. Split the dataset into a training set and a test set. Use a random seed to ensure reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68422c82-b802-4b41-b8e5-ce7970e69555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'path/to/diabetes.csv'  # Replace with the actual path to your CSV file\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Handling missing values (replace with median for numerical features)\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "df_filled = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "\n",
    "# Outlier detection and removal using Isolation Forest\n",
    "outlier_detector = IsolationForest(contamination=0.05, random_state=42)\n",
    "outliers = outlier_detector.fit_predict(df_filled)\n",
    "df_cleaned = df_filled.loc[outliers != -1]\n",
    "\n",
    "# Transform categorical variables into dummy variables (if any)\n",
    "# Example: df_cleaned = pd.get_dummies(df_cleaned, columns=['CategoricalVariable'])\n",
    "\n",
    "# Split the data into features and target variable\n",
    "X = df_cleaned.drop('Outcome', axis=1)\n",
    "y = df_cleaned['Outcome']\n",
    "\n",
    "# Split the data into training and testing sets with a random seed for reproducibility\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Now, X_train, X_test, y_train, y_test can be used for further analysis or modeling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8b1d9d-bd0b-45c7-ab21-57b3a11450a6",
   "metadata": {},
   "source": [
    "Q4. Use a decision tree algorithm, such as ID3 or C4.5, to train a decision tree model on the training set. Use \n",
    "cross-validation to optimize the hyperparameters and avoid overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9a9a39-5275-4db3-8ebe-8027114971f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create a Decision Tree model\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Define hyperparameters to search over\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV for hyperparameter tuning\n",
    "grid_search = GridSearchCV(estimator=dt_model, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\")\n",
    "print(best_params)\n",
    "\n",
    "# Train the model with the best hyperparameters on the entire training set\n",
    "best_dt_model = grid_search.best_estimator_\n",
    "best_dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred_test = best_dt_model.predict(X_test)\n",
    "\n",
    "# Print the accuracy on the test set\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "print(f'Accuracy on Test Set: {accuracy_test:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64943180-0e1b-4951-9efc-f03c52b8f0a3",
   "metadata": {},
   "source": [
    "Q5. Evaluate the performance of the decision tree model on the test set using metrics such as accuracy, \n",
    "precision, recall, and F1 score. Use confusion matrices and ROC curves to visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49eca9b7-d7e6-4d75-8069-b22edfcb67d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_test = best_dt_model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred_test)\n",
    "precision = precision_score(y_test, y_pred_test)\n",
    "recall = recall_score(y_test, y_pred_test)\n",
    "f1 = f1_score(y_test, y_pred_test)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_test)\n",
    "print('\\nConfusion Matrix:\\n', conf_matrix)\n",
    "\n",
    "# ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_test, best_dt_model.predict_proba(X_test)[:, 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (AUC = {:.2f})'.format(roc_auc))\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1333c56-f805-4630-b4e8-ab45bb7dfbd0",
   "metadata": {},
   "source": [
    "Q6. Interpret the decision tree by examining the splits, branches, and leaves. Identify the most important \n",
    "variables and their thresholds. Use domain knowledge and common sense to explain the patterns and \n",
    "trends."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
